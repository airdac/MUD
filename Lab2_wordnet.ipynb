{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/airdac/MUD/blob/main/Copy_of_wordnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ulasnnr8nius"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the NLP and WordNet Introduction Lab!\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------------------------------------------------------------\n",
        "# 1. Introduction to NLP and WordNet\n",
        "# -----------------------------------------------------------------------------------\n",
        "print(\"Welcome to the NLP and WordNet Introduction Lab!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZXsSzO-ZnEFI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in c:\\users\\airdac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.1)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.3.2-cp311-cp311-win_amd64.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: click in c:\\users\\airdac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\airdac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\airdac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in c:\\users\\airdac\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.66.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\airdac\\appdata\\roaming\\python\\python311\\site-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\airdac\\appdata\\roaming\\python\\python311\\site-packages (from gensim) (1.12.0)\n",
            "Collecting smart-open>=1.8.1 (from gensim)\n",
            "  Downloading smart_open-7.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
            "  Downloading wrapt-1.16.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\airdac\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk) (0.4.6)\n",
            "Downloading gensim-4.3.2-cp311-cp311-win_amd64.whl (24.0 MB)\n",
            "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.1/24.0 MB 2.4 MB/s eta 0:00:10\n",
            "   ---------------------------------------- 0.3/24.0 MB 3.4 MB/s eta 0:00:07\n",
            "    --------------------------------------- 0.5/24.0 MB 3.5 MB/s eta 0:00:07\n",
            "    --------------------------------------- 0.6/24.0 MB 3.3 MB/s eta 0:00:08\n",
            "   - -------------------------------------- 0.7/24.0 MB 3.4 MB/s eta 0:00:07\n",
            "   - -------------------------------------- 0.8/24.0 MB 3.5 MB/s eta 0:00:07\n",
            "   - -------------------------------------- 1.2/24.0 MB 4.2 MB/s eta 0:00:06\n",
            "   --- ------------------------------------ 1.8/24.0 MB 5.5 MB/s eta 0:00:05\n",
            "   --- ------------------------------------ 2.4/24.0 MB 6.3 MB/s eta 0:00:04\n",
            "   ---- ----------------------------------- 3.0/24.0 MB 7.0 MB/s eta 0:00:04\n",
            "   ----- ---------------------------------- 3.5/24.0 MB 7.4 MB/s eta 0:00:03\n",
            "   ------ --------------------------------- 4.1/24.0 MB 8.2 MB/s eta 0:00:03\n",
            "   ------- -------------------------------- 4.7/24.0 MB 8.5 MB/s eta 0:00:03\n",
            "   -------- ------------------------------- 5.2/24.0 MB 8.8 MB/s eta 0:00:03\n",
            "   --------- ------------------------------ 5.9/24.0 MB 9.2 MB/s eta 0:00:02\n",
            "   ---------- ----------------------------- 6.5/24.0 MB 9.5 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 7.2/24.0 MB 9.7 MB/s eta 0:00:02\n",
            "   ------------ --------------------------- 7.7/24.0 MB 9.9 MB/s eta 0:00:02\n",
            "   ------------- -------------------------- 8.4/24.0 MB 10.1 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 8.8/24.0 MB 10.3 MB/s eta 0:00:02\n",
            "   --------------- ------------------------ 9.5/24.0 MB 10.5 MB/s eta 0:00:02\n",
            "   ---------------- ----------------------- 10.1/24.0 MB 10.5 MB/s eta 0:00:02\n",
            "   ----------------- ---------------------- 10.7/24.0 MB 11.7 MB/s eta 0:00:02\n",
            "   ------------------ --------------------- 10.9/24.0 MB 12.6 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 11.7/24.0 MB 13.1 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 12.2/24.0 MB 12.9 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 12.9/24.0 MB 13.1 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 13.4/24.0 MB 13.1 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 14.0/24.0 MB 13.1 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 14.5/24.0 MB 13.4 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 15.2/24.0 MB 13.1 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 15.7/24.0 MB 13.1 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 16.3/24.0 MB 13.1 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 16.8/24.0 MB 13.1 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 17.5/24.0 MB 13.1 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 18.1/24.0 MB 13.1 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 18.6/24.0 MB 12.8 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 19.2/24.0 MB 13.4 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 19.7/24.0 MB 12.8 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 20.3/24.0 MB 12.8 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 20.8/24.0 MB 12.8 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 21.4/24.0 MB 12.8 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 22.0/24.0 MB 13.1 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 22.5/24.0 MB 13.1 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 22.9/24.0 MB 13.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  23.6/24.0 MB 13.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.0/24.0 MB 12.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 24.0/24.0 MB 12.4 MB/s eta 0:00:00\n",
            "Downloading smart_open-7.0.1-py3-none-any.whl (60 kB)\n",
            "   ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
            "   ---------------------------------------- 60.8/60.8 kB ? eta 0:00:00\n",
            "Downloading wrapt-1.16.0-cp311-cp311-win_amd64.whl (37 kB)\n",
            "Installing collected packages: wrapt, smart-open, gensim\n",
            "Successfully installed gensim-4.3.2 smart-open-7.0.1 wrapt-1.16.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to C:\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to C:\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to C:\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# First, let's install the necessary libraries\n",
        "%pip install nltk gensim\n",
        "\n",
        "# Import the necessary libraries\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "from scipy.spatial import distance\n",
        "from sklearn.metrics import jaccard_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Download necessary datasets from NLTK\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')  # for tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mKfSm8QtTnK"
      },
      "source": [
        "**Note:** Below shows a table of attribute and their definitions on wordnet.[ref1](https://wordnet.princeton.edu) [/ref2](https://opensource.com/article/20/8/nlp-python-nltk)\n",
        "\n",
        "| Attribute   | Definition                                                                                             | Example                                                                                                                                                                   | Code Example                                                                                          |\n",
        "|-------------|--------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------|\n",
        "| Name        | Name of the synset                                                                                     | Example: The word \"code\" has five synsets with names code.n.01, code.n.02, code.n.03, code.v.01, code.v.02                                                                | `synset.name()`                                                                                      |\n",
        "| POS         | Part of speech of the word for this synset                                                             | The word \"code\" has three synsets in noun form and two in verb form                                                                                                       | `synset.pos()`                                                                                       |\n",
        "| Definition  | Definition of the word (in POS)                                                                        | One of the definitions of \"code\" in verb form is: \"(computer science) the symbolic...\"                             | `synset.definition()`                                                                                |\n",
        "| Examples    | Examples of word's use                                                                                 | One of the examples of \"code\": \"We should encode the message for security reasons\"                                                                                        | `synset.examples()`                                                                                  |\n",
        "| Lemmas      | Other word synsets this word+POC is related to (not strictly synonyms, but can be considered so);...   | Lemmas of code.v.02 (as in \"convert ordinary language into code\") are code.v.02.encipher, code.v.02.cipher,... | `synset.lemmas()`                                                                                    |\n",
        "| Antonyms    | Opposites                                                                                              | Antonym of lemma encode.v.01.encode is decode.v.01.decode                                                                                                                 | `[lemma.antonyms() for lemma in synset.lemmas() if len(lemma.antonyms()) > 0]`                        |\n",
        "| Hypernym    | A broad category that other words fall under                                                           | A hypernym of code.v.01 (as in \"Code the pieces with numbers so that you can identify them later\") is tag.v.01                                                           | `synset.hypernyms()`                                                                                 |\n",
        "| Meronym     | A word that is part of (or subordinate to) a broad category                                            | A meronym of \"computer\" is \"chip\"                                                                                                                                         | `synset.part_meronyms()`                                                                             |\n",
        "| Holonym     | The relationship between a parent word and its subordinate parts                                       | A hyponym of \"window\" is \"computer screen\"                                                                                                                                | `synset.part_holonyms()`                                                                             |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUMs3sCrwfB-"
      },
      "source": [
        "**Note:** A \"synset\" is a single group of synonyms representing one meaning of a word or phrase, while \"synsets\" refer to the full set of these groups that a word can belong to, representing all the possible meanings of the word as organized in WordNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__jCiRQ0xv_3"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------------------------------------------------\n",
        "# 2. Exploring WordNet with NLTK\n",
        "# -----------------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "np4hueOewEpO"
      },
      "outputs": [],
      "source": [
        "## Let's find out what synsets the word 'dog' has\n",
        "## Accessing synsets\n",
        "dog_synsets = wn.synsets('dog')\n",
        "print(\"\\nSynsets for 'dog':\", dog_synsets)\n",
        "## a synset comes within a synset id (f.g. 'dog.n.01' ) which refers to the specific sense of that word. A word could have several senses and synsets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hY9J_Ngkur8O"
      },
      "outputs": [],
      "source": [
        "synset = wn.synset('dog.n.01')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0tGm94CuqoQ"
      },
      "outputs": [],
      "source": [
        "## Let's build a function to print the Attribute table information for a synset.\n",
        "#TODO: fill the \"fill in\" parts\n",
        "def synset_info(synset):\n",
        "    print(\"Name\", synset.name())\n",
        "    print(\"POS:\", synset.pos())\n",
        "    print(\"Definition:\", \"to fill in .......\")\n",
        "    print(\"Examples:\", \"to fill in .......\")\n",
        "    print(\"Lemmas:\", \"to fill in .......\")\n",
        "    print(\"Antonyms:\", \"to fill in .......\")\n",
        "    print(\"Hypernyms:\", \"to fill in .......\")\n",
        "    print(\"Part Holonyms:\", \"to fill in .......\")\n",
        "    print(\"Part Meronyms:\", \"to fill in .......\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rsKWj3VeG93"
      },
      "outputs": [],
      "source": [
        "synset_info(synset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FM9xbhR05HZ"
      },
      "outputs": [],
      "source": [
        "## We found the synsets ids of the word 'dog' . Now we can find the synset of each synset id."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVJIRZonnHc1"
      },
      "outputs": [],
      "source": [
        "## TODO: Find synsets for 'cat'\n",
        "# Uncomment the lines below and fill in the blank\n",
        "# cat_synsets = wn.synsets('____')\n",
        "# print(\"\\nSynsets for 'cat':\", cat_synsets)\n",
        "\n",
        "## TODO: Find the synset_info() of the a selected synset id from 'cat'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7anpRI7dXK-"
      },
      "outputs": [],
      "source": [
        "## Exploring word hierarchies (Hypernyms and Hyponyms)\n",
        "#Build a function to print out the hypernyms and hyponyms of the synsets of the word 'dog' through a loop\n",
        "\n",
        "def print_hypernyms(input_word):\n",
        "  word_synsets = wn.synsets(input_word)\n",
        "  for synset in word_synsets:\n",
        "    #sysnet = ...\n",
        "    #print(\"\\nHypernyms of ',input_word, dog.hypernyms())\n",
        "    #to be filled ...\n",
        "    pass\n",
        "\n",
        "def print_hyponyms(input_word):\n",
        "  word_synsets = wn.synsets(input_word)\n",
        "  #to be filled...\n",
        "  pass\n",
        "\n",
        "\n",
        "## TODO: Explore hypernyms and hyponyms for 'cat'\n",
        "# Replace 'dog' with 'cat' in the example above and explore\n",
        "#Todo, redo the functions above for the word 'cat'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-M8MN8ycl0J"
      },
      "outputs": [],
      "source": [
        "##EXTRA PART\n",
        "##The WordNet corpus reader gives access to the Open Multilingual WordNet,\n",
        "##using ISO-639 language codes. These languages are not loaded by default, but only lazily, when needed.\n",
        "wn.synsets(b'\\xe7\\x8a\\xac'.decode('utf-8'), lang='jpn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5EQ1d9AcsMm"
      },
      "outputs": [],
      "source": [
        "## Lets see the lemma names of spy in japanese\n",
        "wn.synset('spy.n.01').lemma_names('jpn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ih_-KTadARj"
      },
      "outputs": [],
      "source": [
        "## We can print to see which languages the wordnet object has\n",
        "sorted(wn.langs())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QcDsPiCdNE0"
      },
      "outputs": [],
      "source": [
        "## Let's see what is the lemma names of 'dog' first sense in italian\n",
        "wn.synset('dog.n.01').lemma_names('ita')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hr-r8KRNdgXT"
      },
      "outputs": [],
      "source": [
        "## Now we can search for the lemmas of cane in italian\n",
        "wn.lemmas('cane', lang='ita')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3ss3nKRdofp"
      },
      "outputs": [],
      "source": [
        "## we can search for the synonyms of the words as well, in the same or another language!\n",
        "## synonyms of car in english\n",
        "en_synonyms = wn.synonyms('car')\n",
        "print(\"Synonyms of the word car in en language: \",en_synonyms)\n",
        "\n",
        "es_synonyms = wn.synonyms('coche', lang='spa')\n",
        "\n",
        "print(\"Synonyms of the word coche in es language: \",es_synonyms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTOoVaEleJPS"
      },
      "outputs": [],
      "source": [
        "##TODO try it with antonyms (e.g. - > antonyms())\n",
        "## Write your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00P_gEjZnJH_"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------------\n",
        "# 3. Computing Semantic Similarity Between Words\n",
        "# -----------------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_3Y7ms3iX35"
      },
      "outputs": [],
      "source": [
        "## Path similarity\n",
        "dog = wn.synset('dog.n.01')\n",
        "cat = wn.synset('cat.n.01')\n",
        "print(\"\\nPath similarity between 'dog' and 'cat':\", dog.path_similarity(cat))\n",
        "\n",
        "## TODO: Compute Wu-Palmer similarity between 'dog' and 'cat'\n",
        "# Uncomment the lines below and fill in the blank\n",
        "# print(\"Wu-Palmer similarity between 'dog' and 'cat':\", dog.wup_similarity(cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzQjr7Zi3Ti1"
      },
      "outputs": [],
      "source": [
        "##Comparing similarities is a fundamental process used to identify commonalities between two text segments.\n",
        "##This technique is widely applied in various domains, including search engines, chatbots, and beyond,\n",
        "##serving as a crucial component for enhancing user interactions and information retrieval.\n",
        "\n",
        "syn1 = wn.synsets('football')\n",
        "syn2 = wn.synsets('soccer')\n",
        "\n",
        "# A word may have multiple synsets, so need to compare each synset of word1 with synset of word2\n",
        "for s1 in syn1:\n",
        "    for s2 in syn2:\n",
        "        print(\"Path similarity of: \")\n",
        "        print(s1, '(', s1.pos(), ')', '[', s1.definition(), ']')\n",
        "        print(s2, '(', s2.pos(), ')', '[', s2.definition(), ']')\n",
        "        print(\"   is\", s1.path_similarity(s2))\n",
        "        print()\n",
        "\n",
        "##Todo: write a function to recieve two words and perform the similarities of their synsets. Try it with 'king' 'queen' , 'car' 'engine' , 'good' 'bad' and 'black' 'white'.\n",
        "\n",
        "##..... write it here below (hint, you can use the above code to produce this function!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSK-3EWEnKZF"
      },
      "outputs": [],
      "source": [
        "print(\"\\n-- Document Similarity Based on WordNet Synsets --\")\n",
        "\n",
        "## Introduction to computing document similarity using WordNet\n",
        "## Example and Practice: Define a function to compute the similarity between two documents\n",
        "def document_similarity(doc1, doc2):\n",
        "    \"\"\"\n",
        "    Compute document similarity using WordNet synset similarities for pairs of words.\n",
        "    \"\"\"\n",
        "    synsets1 = [wn.synsets(word) for word in nltk.word_tokenize(doc1)]\n",
        "    synsets2 = [wn.synsets(word) for word in nltk.word_tokenize(doc2)]\n",
        "\n",
        "    # Flatten the list of synsets and filter out None\n",
        "    synsets1 = [ss for sublist in synsets1 for ss in sublist if ss]\n",
        "    synsets2 = [ss for sublist in synsets2 for ss in sublist if ss]\n",
        "\n",
        "    score, count = 0.0, 0\n",
        "\n",
        "    # For each synset in both documents, find the maximum similarity value\n",
        "    for synset1 in synsets1:\n",
        "        max_score = max([synset1.path_similarity(synset2) or 0 for synset2 in synsets2])\n",
        "        if max_score > 0:\n",
        "            score += max_score\n",
        "            count += 1\n",
        "\n",
        "    # Average the scores\n",
        "    score /= count\n",
        "    return score\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHh7P_bNhqXp"
      },
      "outputs": [],
      "source": [
        "## Test the function with two simple documents\n",
        "doc1 = \"Dogs are awesome.\"\n",
        "doc2 = \"Cats are amazing.\"\n",
        "print(\"Document similarity:\", document_similarity(doc1, doc2))\n",
        "\n",
        "# -----------------------------------------------------------------------------------\n",
        "# Wrap-up and Q&A\n",
        "# -----------------------------------------------------------------------------------\n",
        "print(\"\\nThank you for participating in the lab! Feel free to experiment with the code and explore further. If you have any questions, now is a great time to ask.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B43z1yc_hrqj"
      },
      "outputs": [],
      "source": [
        "##Todo : Try to find the similarities of more documents. does it work for a text with multiple sentences?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
